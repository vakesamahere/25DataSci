import requests
import selenium
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import re
import pandas as pd
import logging
import os
from datetime import datetime
import time

# 创建logs目录(如果不存在)
if not os.path.exists("logs"):
    os.makedirs("logs")

# 设置日志配置
log_filename = f"logs/box_office_crawler_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

logger.info("爬虫程序启动")

try:
    chrome_options = webdriver.ChromeOptions()
    # chrome_options.add_argument('--headless')  # 无头模式
    
    logger.info("初始化Chrome浏览器")
    driver = webdriver.Chrome(service=Service(), options=chrome_options)
    
    # test
    url = "https://piaofang.maoyan.com/rankings/year"
    logger.info(f"访问URL: {url}")
    driver.get(url)
    
    # 等待页面加载
    logger.info("等待页面加载")
    driver.implicitly_wait(10)
    
    # 获取页面内容
    page_source = driver.page_source
    
    # 确保snapshot目录存在
    if not os.path.exists("snapshot"):
        os.makedirs("snapshot")
    
    # 保存到snapshot.html
    logger.info("保存页面快照")
    with open("snapshot/test.html", "w", encoding="utf-8") as f:
        f.write(page_source)
    
    # 获取所有年份的按钮div.select-year > ul > li["data-com"="canTouch"], text = "\d+年"
    logger.info("查找年份按钮")
    year_buttons = driver.find_elements(By.CSS_SELECTOR, "div.select-year > ul > li[data-com='canTouch']")
    pattern = r"\d+年"
    
    logger.info(f"找到 {len(year_buttons)} 个可能的年份按钮")
    
    # 新建一个df
    df = pd.DataFrame(columns=["Title", "Box Office", "Average Price"])
    
    for year_button in year_buttons:
        year_text = year_button.text
        if re.match(pattern, year_text):
            logger.info(f"处理年份: {year_text}")
            
            # 点击年份按钮
            logger.debug(f"点击{year_text}按钮")
            year_button.click()
            
            # 等待页面加载
            driver.implicitly_wait(10)
            
            # 获取当前年份的票房数据，所有行#ranks-list > ul.row
            rows = driver.find_elements(By.CSS_SELECTOR, "#ranks-list > ul.row")
            """
            <li class="col0">1</li> 序号，不用管
            <li class="col1"> 标题
                <p class="first-line">哪吒之魔童闹海</p> 保存这个
                <p class="second-line">2025-01-29 上映</p>
            </li>
            <li class="col2 tr">1543130</li> 票房(万元) 保存这个
            <li class="col3 tr">47.646793</li> 平均票价(元) 保存这个
            <li class="col4 tr">24</li>
            """
            logger.info(f"{year_text}找到 {len(rows)} 条票房数据")
            time.sleep(5)  # 等待页面稳定
            
            for row in rows:
                try:
                    # title = row.find_element(By.CSS_SELECTOR, "li.col1 > p.first-line").text
                    # box_office = row.find_element(By.CSS_SELECTOR, "li.col2.tr").text
                    # average_price = row.find_element(By.CSS_SELECTOR, "li.col3.tr").text
                    # average_people = row.find_element(By.CSS_SELECTOR, "li.col4.tr").text
                    title = row.find_element(By.CSS_SELECTOR, "li.col1 > p.first-line").text
                    logger.info(f"=====处理电影: {title}")
                    box_office = row.find_element(By.CSS_SELECTOR, "li.col2").text
                    logger.info(f"\t\t票房: {box_office}万元")
                    average_price = row.find_element(By.CSS_SELECTOR, "li.col3").text
                    logger.info(f"\t\t平均票价: {average_price}元")
                    # average_people = row.find_element(By.CSS_SELECTOR, "li.col4").text
                    # logger.info(f"\t\t场均人数: {average_people}")
                    # 添加到df 用concat
                    temp_df = pd.DataFrame({
                        "Title": [title],
                        "Box Office": [box_office],
                        "Average Price": [average_price],
                        # "Average People": [average_people]
                    })
                    df = pd.concat([df, temp_df], ignore_index=True)
                except Exception as e:
                    logger.error(f"处理电影数据时出错: {str(e)}")
                    input("按回车键继续...")  # 暂停，等待用户查看错误信息
            df.to_csv("data/box_office_data.csv", index=False, encoding="utf-8-sig")
    
    # 确保data目录存在
    if not os.path.exists("data"):
        os.makedirs("data")
    
    # 保存到csv
    logger.info(f"将数据保存到CSV文件，共 {len(df)} 条记录")
    df.to_csv("data/box_office_data.csv", index=False, encoding="utf-8-sig")
    logger.info("数据已保存到 data/box_office_data.csv")

    input("按回车键继续...")
    
except Exception as e:
    logger.error(f"程序执行出错: {str(e)}", exc_info=True)
    
finally:
    # 关闭浏览器
    logger.info("关闭浏览器")
    try:
        driver.quit()
    except Exception as e:
        logger.error(f"关闭浏览器时出错: {str(e)}")
    
    logger.info("爬虫程序结束")